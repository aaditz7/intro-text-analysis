{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework\n",
    "\n",
    "1. Read @Brezina2018 [ch. 2, pp. 41--65].\n",
    "2. Choose 3 books of Pausanias and calculate the most common tokens, types, and lemmata for each. In a paragraph or so, describe your findings relative to the work we have done in class today.\n",
    "3. Using your findings from 2., write a short (1-page) evaluation of one of the books of Pausanias that you have analyzed. Does your qualitative -- which is not to say \"subjective\" -- experience of reading the text cohere with your quantitative evaluation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install MyCapytain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MyCapytain.resources.texts.local.capitains.cts import CapitainsCtsText\n",
    "\n",
    "with open(\"../tei/tlg0525.tlg001.perseus-eng2.xml\") as f:\n",
    "    text = CapitainsCtsText(urn=\"urn:cts:greekLit:tlg0525.tlg001.perseus-eng2\", resource=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from lxml import etree\n",
    "from MyCapytain.common.constants import Mimetypes\n",
    "\n",
    "urns = []\n",
    "raw_xmls = []\n",
    "unannotated_strings = []\n",
    "\n",
    "for ref in text.getReffs(level=len(text.citation)):\n",
    "    urn = f\"{text.urn}:{ref}\"\n",
    "    node = text.getTextualNode(ref)\n",
    "    raw_xml = node.export(Mimetypes.XML.TEI)\n",
    "    tree = node.export(Mimetypes.PYTHON.ETREE)\n",
    "    s = etree.tostring(tree, encoding=\"unicode\", method=\"text\")\n",
    "\n",
    "    urns.append(urn)\n",
    "    raw_xmls.append(raw_xml)\n",
    "    unannotated_strings.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install the latest version of numpy 1, instead of pandas' numpy 2\n",
    "%pip install numpy==1.26.4\n",
    "\n",
    "%pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "d = {\n",
    "    \"urn\": pd.Series(urns, dtype=\"string\"),\n",
    "    \"raw_xml\": raw_xmls,\n",
    "    \"unannotated_strings\": pd.Series(unannotated_strings, dtype=\"string\")\n",
    "}\n",
    "pausanias_df = pd.DataFrame(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See https://pandas.pydata.org/docs/reference/api/pandas.Series.str.split.html for\n",
    "# panda's string-splitting utilities; it splits on whitespace by default\n",
    "pausanias_df['whitespaced_tokens'] = pausanias_df['unannotated_strings'].str.split()\n",
    "\n",
    "pausanias_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_book_of_pausanias(df: pd.DataFrame, book_n: int):\n",
    "    return df[df['urn'].str.startswith(f\"urn:cts:greekLit:tlg0525.tlg001.perseus-eng2:{book_n}\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "book7 = get_book_of_pausanias(pausanias_df, 7)\n",
    "book1 = get_book_of_pausanias(pausanias_df, 1)\n",
    "book3 = get_book_of_pausanias(pausanias_df, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "book7['whitespaced_tokens'].explode().count()\n",
    "len(book7['whitespaced_tokens'].explode().unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "types = book7['whitespaced_tokens'].explode()\n",
    "\n",
    "type_counts = Counter(types)\n",
    "\n",
    "print(type_counts.most_common(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "types = book1['whitespaced_tokens'].explode()\n",
    "\n",
    "type_counts = Counter(types)\n",
    "\n",
    "print(type_counts.most_common(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "types = book3['whitespaced_tokens'].explode()\n",
    "\n",
    "type_counts = Counter(types)\n",
    "\n",
    "print(type_counts.most_common(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -m spacy download en\n",
    "%run -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TYPES WITH TOKEN COUNT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = nlp.tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def commontypes(df: pd.DataFrame):\n",
    "    from collections import Counter\n",
    "    \n",
    "    df['tokens'] = df['unannotated_strings'].apply(tokenizer)\n",
    "\n",
    "    tokens_list = [t.text for t in df['tokens'].explode() if not t.is_stop and t.is_alpha]\n",
    "\n",
    "    type_counts = Counter(tokens_list)\n",
    "\n",
    "    print('Type count: ' + str(len(type_counts)))\n",
    "    print('Token count: ' + str(sum(type_counts.values())))\n",
    "    print (type_counts.most_common(100))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "commontypes(book7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "commontypes(book1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "commontypes(book3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LEMMATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def commonlemmata(df: pd.DataFrame):\n",
    "    from collections import Counter\n",
    "    raw_texts = [t for t in df['unannotated_strings']]\n",
    "    annotated_texts = nlp.pipe(raw_texts, batch_size=100)\n",
    "    df['nlp_docs'] = list(annotated_texts)\n",
    "    lemmata = [t.lemma_ for t in df['nlp_docs'].explode() if not t.is_stop and t.is_alpha]\n",
    "\n",
    "    lemmata_counts = Counter(lemmata)\n",
    "\n",
    "    return lemmata_counts.most_common(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "commonlemmata(book7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "commonlemmata(book1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "commonlemmata(book3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Findings in relation to work done in class:\n",
    "\n",
    "\n",
    "I believe the transition from tokens to types to lemmata is extremely critical for quantitative textual analysis to be meaningful. For example, the words 'men' and 'man' are very similar and pretty much represent the same thing/ have the same implications. Thus, by combining their counts through lemmatization, we are able to get a much more accurate and insightful idea of the text to be studied. Especially in the context of these books where proper nouns take different forms (Athens/ Athenians, Greece/ Greek), the aforementioned process is helpful to correlate closely resembled words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 3. Summary of Book 1:\n",
    "\n",
    "\n",
    "In Book 1, Pausanias focuses on Attica, the region of Athens, one of the most famous and culturally significant parts of ancient Greece. Athenians (Athens), Greeks and Apollo are some of the most recurring lemmata in book 1, almost certainly iterating that the setting of the book is Athens, Greece. This is easily discernible given the frequency of appearances of these words in our quantitative analysis.\n",
    "\n",
    "Pausanias provides an extensive description of the Acropolis, the citadel of Athens, and its significant temples and monuments. Pausanias details the art and sculptures housed in these temples, which we can clearly link to our quantitative analysis- given that temples, statues and sanctuaries were in the top 20 most common words used in the book. Pausanias describes the Athenian Agora, the social and political heart of the city, pointing out the various temples, statues, and stoas. Throughout Athens, Pausanias records numerous statues of gods, heroes, and important figures. \n",
    "\n",
    "Pausanias is particularly interested in the temples of Athens and surrounding Attica. The temple of Athena on the Acropolis, the temple of Olympian Zeus, and the sanctuary at Eleusis are key highlights of his description. Gods like Athena, Zeus, and Apollo are central to the religious life of the Athenians, as Pausanias illustrates by detailing the architecture and religious ceremonies.\n",
    "\n",
    "Pausanias frequently refers to historical events such as the wars that shaped the history of Athens, including the Battle of Marathon. He also mentions various kings, both mythical and historical, like Theseus, who is closely tied to the legends of Athens. His discussions of war and leadership reflect the Athenians' military prowess and the legacy of their past victories. This is evident from our quantitative analysis where the words 'war', 'king', 'kill' appeared frequently- all together indicative of conquest. Thus, I can reiterate that my quantitative analysis matches the qualitative observation through reading about historical events.\n",
    "\n",
    "The frequent references to family relationships, particularly sons and daughters, echo Pausanias' recounting of Greek myths and genealogies. For example, Athena (who is symbolically considered the daughter of Zeus) is revered in Athens, and mythological stories often emphasize the familial connections between gods and heroes. The sons and daughters of kings and gods feature prominently in the stories of the city. That is why our quantitative analysis of the most common lemmata featured sons and daughters- simply because of the way Greek mythological gods are referred to in society. \n",
    "\n",
    "Overall, Pausanias intersperses his description with historical accounts of wars, political events, and important figures that shaped Athens. He often contrasts Athens' present with its glorious past, lamenting how many of the city's wonders were destroyed or decayed over time. I believe the quantitative analysis conducted does give reasonable insight into the contents of book 1 without reading- as by grouping themed words together- we can assert the setting, history and other important events and landmarks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
